<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Audio Context</title>
</head>
<body>
    <h1>Audio Context</h1>
    <h2 style="color: red;">请使用FF测试，Chrome有跨源限制</h2>
    <p>混响：声波在室内传播时，要被墙壁、天花板、地板等障碍物反射，每反射一次都要被障碍物吸收一些。这样，当声源停止发声后，声波在室内要经过多次反射和吸收，最后才消失，我们就感觉到声源停止发声后声音还继续一段时间。这种现象叫做混响</p>
    <hr>
    <button id="btnPlay1" disabled="disabled">播放1</button><span>源直接连接到输出设备</span>
    <hr>
    <button id="btnPlay2" disabled="disabled">播放2</button><span>源先连接到GainNode（增益节点）再连接到输出设备</span>
    <hr>
    <button id="btnPlay3" disabled="disabled">播放3</button><span>源先连接到GainNode（增益节点），再连接DynamicsCompressorNode（压缩器节点）最后连接到输出设备</span>
    

    <script>
    // 获取AudioContext
    window.context = getAudiocontext();
    // 获取音频数据
    window.source = null;

    // 执行
    getBufs();


    /**
     * 获取AudioContext
     * @return {AudioContext} andio元素相关的环境对象
     */
    function getAudiocontext() {
        window.AudioContext = (window.AudioContext || window.webkitAudioContext);
        if(window.AudioContext) {
            return new window.AudioContext();
        } else {
            console.log('not support web audio api');
        }
    }

    /**
     * 播放
     * @param {Integer} 1: 多个source直接连接输出设备 2: 多个source通过GainNode再连接输出设备
     * @return nth
     */
    function getBufs() {
        var audioURL = 'mp1.mp3'; // 这里替换为音频文件URL
        var xhr1 = new XMLHttpRequest();
        var bufs = [];

        xhr1.open('GET', audioURL, true);
        xhr1.responseType = 'arraybuffer'; // XMLHttpRequest 2的新东西
        xhr1.onload = function() {
            // 音频数据在xhr.response中，而不是xhr.requestText
            bufs.push(xhr1.response);
            var audioURL = 'mp2.mp3'; // 这里替换为音频文件URL
            var xhr2 = new XMLHttpRequest();
            xhr2.open('GET', audioURL, true);
            xhr2.responseType = 'arraybuffer'; // XMLHttpRequest 2的新东西
            xhr2.onload = function() {
                bufs.push(xhr2.response);
                var audioURL = 'mp3.mp3'; // 这里替换为音频文件URL
                var xhr3 = new XMLHttpRequest();
                xhr3.open('GET', audioURL, true);
                xhr3.responseType = 'arraybuffer'; // XMLHttpRequest 2的新东西
                xhr3.onload = function() {
                    bufs.push(xhr3.response);
                    
                    // 添加事件处理器
                    addHandler(bufs);
                }
                xhr3.send();
            }
            xhr2.send();
        }
        xhr1.send();
    }
    </script>
    <!-- 事件监听 -->
    <script>
    function addHandler(bufs) {
        window.clickTimes = [0, 0, 0];
        window.comNode = context.createDynamicsCompressor();
        window.gainNode1 = context.createGain();
        window.gainNode2 = context.createGain();

        var btnPlay1 = document.getElementById("btnPlay1");
        var btnPlay2 = document.getElementById("btnPlay2");
        var btnPlay3 = document.getElementById("btnPlay3");

        btnPlay1.onclick = function() {
            if (window.clickTimes[0] === 3) {
                location.reload();
            }
            context.decodeAudioData(bufs[window.clickTimes[0]++], function(buffer) {
                source = context.createBufferSource();
                source.buffer = buffer;
                // 源直接连接到输出设备
                source.connect(context.destination);
                source.start(0);
            });
        }
        btnPlay2.onclick = function() {
            if (window.clickTimes[1] === 3) {
                location.reload();
            }
            context.decodeAudioData(bufs[window.clickTimes[1]++], function(buffer) {
                source = context.createBufferSource();
                source.buffer = buffer;
                // 将源与gain相连接
                source.connect(window.gainNode1);
                // 将gain与目标相连接
                window.gainNode1.connect(context.destination);
                source.start(0);
            });
        }
        btnPlay3.onclick = function() {
            if (window.clickTimes[2] === 3) {
                location.reload();
            }
            context.decodeAudioData(bufs[window.clickTimes[2]++], function(buffer) {
                source = context.createBufferSource();
                source.buffer = buffer;
                // 将源与gain相连接
                source.connect(window.gainNode2);
                // 将gain与压缩器相连接
                window.gainNode2.connect(window.comNode);   // 同一个压缩器
                // 将压缩器与目标相连接
                window.comNode.connect(context.destination);
                source.start(0);
            });
        }

        btnPlay1.disabled = false;
        btnPlay2.disabled = false;
        btnPlay3.disabled = false;
    }
    </script>
</body>
</html>